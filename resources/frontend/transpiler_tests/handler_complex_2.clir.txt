CLIR
========
[main__specialized]
function u0:0(i64) -> i64 tail {
    ss0 = explicit_slot 8
    gv0 = symbol colocated userextname0
    sig0 = (i64, i64) -> i64 tail
    sig1 = (i64, i64, i64) -> i64 tail
    sig2 = (i64, i64, i64, i64, i64, i64, i64) -> i64 apple_aarch64
    sig3 = (i64, i64) -> i64 tail
    sig4 = (i64, i64, i64, i64) apple_aarch64
    sig5 = (i64, i64, i64, i64) -> i64 tail
    sig6 = (i64, i64) -> i64 tail
    sig7 = (i64, i64) -> i64 apple_aarch64
    fn0 = colocated u0:21 sig0
    fn1 = colocated u0:19 sig1
    fn2 = u0:6 sig2
    fn3 = colocated u0:23 sig3
    fn4 = u0:7 sig4
    fn5 = u0:12 sig5
    fn6 = colocated u0:25 sig6
    fn7 = u0:1 sig7

block0(v0: i64):
    v1 = global_value.i64 gv0
    v2 = iadd_imm v1, 8
    v3 = iconst.i64 2
    v4 = ishl_imm v3, 1  ; v3 = 2
    v5 = iconst.i64 3
    v6 = iconst.i64 3
    v7 = func_addr.i64 fn0
    v8 = iadd_imm v7, 3
    v9 = func_addr.i64 fn1
    stack_store v0, ss0
    v10 = stack_addr.i64 ss0
    v11 = call fn2(v10, v2, v4, v5, v6, v8, v9)  ; v5 = 3, v6 = 3
    v12 = stack_load.i64 ss0
    v13 = load.i64 v11
    v14 = func_addr.i64 fn3
    v15 = iadd_imm v14, 3
    v16 = iconst.i64 3
    v17 = iconst.i64 0
    call fn4(v13, v15, v16, v17)  ; v16 = 3, v17 = 0
    v18 = load.i64 v13
    v19 = func_addr.i64 fn6
    v20 = iadd_imm v19, 3
    stack_store v12, ss0
    v21 = stack_addr.i64 ss0
    v22 = call fn7(v20, v21)
    v23 = stack_load.i64 ss0
    v24 = iadd_imm v11, 1
    v25 = iadd_imm v23, -8
    store aligned v24, v25
    v26 = isub v12, v25
    v27 = load.i64 v18+8
    v28 = ishl_imm v27, 3
    v29 = iadd v28, v26
    v30 = ushr_imm v29, 3
    store v30, v18+8
    v31 = call fn5(v25, v18, v22, v13)
    v32 = load.i64 v31
    v33 = iadd_imm v31, 8
    v34 = sshr_imm v32, 1
    return v34
}


[main$__lambda_0__cps]
function u0:0(i64, i64) -> i64 tail {
    ss0 = explicit_slot 8
    sig0 = (i64, i64, i64) -> i64 tail

block0(v0: i64, v1: i64):
    v2 = load.i64 v0
    v3 = load.i64 v0+8
    v4 = sshr_imm v3, 1
    v5 = sshr_imm v2, 1
    v6 = imul v4, v5
    v7 = ishl_imm v6, 1
    v8 = iadd_imm v0, 8
    store v7, v8
    v9 = load.i64 v1+8
    v10 = ishl_imm v9, 3
    v11 = iadd v0, v10
    v12 = load.i64 v1
    return_call_indirect sig0, v12(v11, v1, v8)
}


[main$__lambda_1__cps]
function u0:0(i64, i64) -> i64 tail {
    ss0 = explicit_slot 8
    sig0 = (i64, i64) -> i64 apple_aarch64
    sig1 = (i64, i64) -> i64 tail
    sig2 = (i64, i64, i64) -> i64 apple_aarch64
    fn0 = u0:1 sig0
    fn1 = %Memmove sig2

block0(v0: i64, v1: i64):
    v2 = load.i64 v0
    v3 = load.i64 v0+8
    v4 = load.i64 v0+16
    v5 = sshr_imm v2, 1
    v6 = sshr_imm v3, 1
    v7 = imul v5, v6
    v8 = iconst.i64 0
    v9 = ishl_imm v8, 1  ; v8 = 0
    v10 = iconst.i64 3
    v11 = ishl_imm v10, 1  ; v10 = 3
    v12 = ishl_imm v7, 1
    v13 = iadd_imm v0, -8
    store aligned v12, v13
    v14 = iadd_imm v13, -8
    store aligned v11, v14
    v15 = iadd_imm v14, -8
    store aligned v9, v15
    stack_store v15, ss0
    v16 = stack_addr.i64 ss0
    v17 = call fn0(v4, v16)
    v18 = stack_load.i64 ss0
    v19 = iadd_imm v18, 24
    v20 = isub v0, v18
    v21 = call fn1(v19, v18, v20)
    v22 = isub v0, v19
    v23 = load.i64 v1+8
    v24 = ishl_imm v23, 3
    v25 = iadd v24, v22
    v26 = ushr_imm v25, 3
    store v26, v1+8
    return_call_indirect sig1, v17(v19, v1)
}


[main$__lambda_2__cps]
function u0:0(i64, i64) -> i64 tail {
    ss0 = explicit_slot 8
    sig0 = (i64, i64, i64) -> i64 apple_aarch64
    sig1 = (i64, i64) -> i64 tail
    sig2 = (i64, i64) -> i64 tail
    sig3 = (i64, i64, i64, i64, i64, i64, i64) -> i64 apple_aarch64
    sig4 = (i64, i64) -> i64 tail
    fn0 = %Memmove sig0
    fn1 = colocated u0:14 sig1
    fn2 = colocated u0:17 sig2
    fn3 = u0:4 sig3

block0(v0: i64, v1: i64):
    v2 = load.i64 v0
    v3 = iconst.i64 5
    v4 = ishl_imm v3, 1  ; v3 = 5
    v5 = iadd_imm v0, -8
    store aligned v4, v5
    v6 = iadd_imm v5, 8
    v7 = isub v0, v5
    v8 = call fn0(v6, v5, v7)
    v9 = isub v0, v6
    v10 = load.i64 v1+8
    v11 = ishl_imm v10, 3
    v12 = iadd v11, v9
    v13 = ushr_imm v12, 3
    store v13, v1+8
    v14 = iconst.i64 1
    v15 = func_addr.i64 fn1
    v16 = func_addr.i64 fn2
    v17 = iconst.i64 0
    v18 = call fn3(v2, v17, v6, v1, v14, v15, v16)  ; v17 = 0, v14 = 1
    v19 = load.i64 v18
    v20 = load.i64 v18+8
    v21 = load.i64 v18+16
    return_call_indirect sig4, v19(v20, v21)
}


[__main__]
function u0:0() -> i64 fast {
    sig0 = () -> i64 apple_aarch64
    sig1 = (i64) -> i64 tail
    fn0 = u0:2 sig0
    fn1 = colocated u0:20 sig1

block0:
    v0 = call fn0()
    v1 = call fn1(v0)
    return v1
}
