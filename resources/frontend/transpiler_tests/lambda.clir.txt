CLIR
========
[main__specialized]
function u0:0(i64) -> i64 tail {
    ss0 = explicit_slot 8
    sig0 = (i64, i64) -> i64 tail
    sig1 = (i64) -> i64 apple_aarch64
    sig2 = () -> i64 apple_aarch64
    sig3 = (i64, i64) -> i64 apple_aarch64
    sig4 = (i64, i64) -> i64 tail
    fn0 = colocated u0:23 sig0
    fn1 = u0:0 sig1
    fn2 = colocated u0:14 sig2
    fn3 = u0:1 sig3

block0(v0: i64):
    v1 = iconst.i64 1
    v2 = func_addr.i64 fn0
    v3 = iconst.i64 1
    v4 = iadd_imm v2, 3
    v5 = ishl_imm v1, 1  ; v1 = 1
    v6 = iconst.i64 3
    v7 = call fn1(v6)  ; v6 = 3
    store aligned v4, v7
    store aligned v3, v7+8  ; v3 = 1
    store aligned v5, v7+16
    v8 = iconst.i64 2
    v9 = ishl_imm v8, 1  ; v8 = 2
    v10 = iadd_imm v0, -8
    store aligned v9, v10
    v11 = call fn2()
    v12 = iadd_imm v7, 1
    stack_store v10, ss0
    v13 = stack_addr.i64 ss0
    v14 = call fn3(v12, v13)
    v15 = stack_load.i64 ss0
    v16 = call_indirect sig4, v14(v15, v11)
    v17 = load.i64 v16
    v18 = iadd_imm v16, 8
    v19 = sshr_imm v17, 1
    return v19
}


[main$__lambda_0__cps]
function u0:0(i64, i64) -> i64 tail {
    ss0 = explicit_slot 8
    sig0 = (i64, i64, i64) -> i64 tail

block0(v0: i64, v1: i64):
    v2 = load.i64 v0
    v3 = load.i64 v0+8
    v4 = sshr_imm v3, 1
    v5 = sshr_imm v2, 1
    v6 = iadd v4, v5
    v7 = ishl_imm v6, 1
    v8 = iadd_imm v0, 8
    store v7, v8
    v9 = load.i64 v1+8
    v10 = ishl_imm v9, 3
    v11 = iadd v0, v10
    v12 = load.i64 v1
    return_call_indirect sig0, v12(v11, v1, v8)
}


[__main__]
function u0:0() -> i64 fast {
    sig0 = () -> i64 apple_aarch64
    sig1 = (i64) -> i64 tail
    fn0 = u0:2 sig0
    fn1 = colocated u0:22 sig1

block0:
    v0 = call fn0()
    v1 = call fn1(v0)
    return v1
}
