CLIR
========
[main__specialized]
function u0:0(i64) -> i64 tail {
    ss0 = explicit_slot 8
    gv0 = symbol colocated userextname0
    gv1 = symbol colocated userextname7
    gv2 = symbol colocated userextname9
    sig0 = (i64, i64) -> i64 tail
    sig1 = (i64, i64) -> i64 tail
    sig2 = (i64, i64) -> i64 tail
    sig3 = (i64, i64, i64) -> i64 tail
    sig4 = (i64, i64, i64, i64, i64, i64, i64) -> i64 apple_aarch64
    sig5 = (i64, i64, i64) apple_aarch64
    sig6 = (i64, i64) -> i64 tail
    sig7 = (i64, i64) -> i64 tail
    sig8 = (i64, i64, i64) apple_aarch64
    sig9 = (i64, i64, i64, i64) -> i64 tail
    sig10 = (i64, i64) -> i64 tail
    sig11 = (i64, i64) -> i64 apple_aarch64
    fn0 = colocated u0:22 sig0
    fn1 = colocated u0:24 sig1
    fn2 = colocated u0:30 sig2
    fn3 = colocated u0:20 sig3
    fn4 = u0:6 sig4
    fn5 = u0:7 sig5
    fn6 = colocated u0:32 sig6
    fn7 = colocated u0:34 sig7
    fn8 = u0:8 sig8
    fn9 = u0:13 sig9
    fn10 = colocated u0:28 sig10
    fn11 = u0:1 sig11

block0(v0: i64):
    v1 = global_value.i64 gv0
    v2 = iadd_imm v1, 8
    v3 = iconst.i64 0
    v4 = ishl_imm v3, 1  ; v3 = 0
    v5 = func_addr.i64 fn0
    v6 = iadd_imm v5, 3
    v7 = func_addr.i64 fn1
    v8 = iadd_imm v7, 3
    v9 = func_addr.i64 fn2
    v10 = iadd_imm v9, 3
    v11 = func_addr.i64 fn3
    stack_store v0, ss0
    v12 = stack_addr.i64 ss0
    v13 = call fn4(v12, v2, v4, v6, v8, v10, v11)
    v14 = stack_load.i64 ss0
    v15 = symbol_value.i64 gv1
    v16 = iadd_imm v15, 8
    v17 = iadd_imm v16, 3
    v18 = func_addr.i64 fn6
    v19 = iadd_imm v18, 3
    call fn5(v13, v17, v19)
    v20 = symbol_value.i64 gv2
    v21 = iadd_imm v20, 8
    v22 = iadd_imm v21, 3
    v23 = func_addr.i64 fn7
    v24 = iadd_imm v23, 3
    call fn5(v13, v22, v24)
    v25 = load.i64 v13
    v26 = func_addr.i64 fn10
    v27 = iadd_imm v26, 3
    stack_store v14, ss0
    v28 = stack_addr.i64 ss0
    v29 = call fn11(v27, v28)
    v30 = stack_load.i64 ss0
    v31 = isub v14, v30
    v32 = load.i64 v25+8
    v33 = ishl_imm v32, 3
    v34 = iadd v33, v31
    v35 = ushr_imm v34, 3
    store v35, v25+8
    v36 = call fn9(v30, v25, v29, v13)
    v37 = load.i64 v36
    v38 = iadd_imm v36, 8
    v39 = sshr_imm v37, 1
    return v39
}


[main$__lambda_0__cps]
function u0:0(i64, i64) -> i64 tail {
    ss0 = explicit_slot 8
    sig0 = (i64) -> i64 apple_aarch64
    sig1 = (i64, i64, i64) -> i64 tail
    fn0 = u0:0 sig0

block0(v0: i64, v1: i64):
    v2 = load.i64 v0
    v3 = iconst.i64 0
    v4 = call fn0(v3)  ; v3 = 0
    v5 = iadd_imm v4, 1
    v6 = iadd_imm v0, 0
    store v5, v6
    v7 = load.i64 v1+8
    v8 = ishl_imm v7, 3
    v9 = iadd v0, v8
    v10 = load.i64 v1
    return_call_indirect sig1, v10(v9, v1, v6)
}


[main$__lambda_1__cps]
function u0:0(i64, i64) -> i64 tail {
    ss0 = explicit_slot 8
    sig0 = (i64) -> i64 apple_aarch64
    sig1 = (i64, i64, i64) -> i64 tail
    fn0 = u0:0 sig0

block0(v0: i64, v1: i64):
    v2 = load.i64 v0
    v3 = iconst.i64 2
    v4 = call fn0(v3)  ; v3 = 2
    store aligned v2, v4
    store aligned v2, v4+8
    v5 = iadd_imm v4, 1
    v6 = iadd_imm v0, 0
    store v5, v6
    v7 = load.i64 v1+8
    v8 = ishl_imm v7, 3
    v9 = iadd v0, v8
    v10 = load.i64 v1
    return_call_indirect sig1, v10(v9, v1, v6)
}


[main$__lambda_10__cps]
function u0:0(i64, i64) -> i64 tail {
    ss0 = explicit_slot 8
    gv0 = symbol colocated userextname0
    gv1 = symbol colocated userextname1
    gv2 = symbol colocated userextname5
    gv3 = symbol colocated userextname1
    gv4 = symbol colocated userextname5
    gv5 = symbol colocated userextname1
    gv6 = symbol colocated userextname6
    gv7 = symbol colocated userextname1
    gv8 = symbol colocated userextname7
    sig0 = (i64, i64) -> i64 tail
    sig1 = (i64, i64) -> i64 tail
    sig2 = (i64, i64, i64, i64, i64, i64, i64) -> i64 apple_aarch64
    sig3 = (i64, i64) -> i64 tail
    sig4 = (i64, i64) -> i64 tail
    sig5 = (i64, i64) -> i64 tail
    sig6 = (i64, i64, i64, i64, i64, i64, i64) -> i64 apple_aarch64
    sig7 = (i64, i64) -> i64 tail
    sig8 = (i64, i64) -> i64 tail
    sig9 = (i64, i64) -> i64 tail
    sig10 = (i64, i64, i64, i64, i64, i64, i64) -> i64 apple_aarch64
    sig11 = (i64, i64) -> i64 tail
    sig12 = (i64, i64) -> i64 tail
    sig13 = (i64, i64) -> i64 tail
    sig14 = (i64, i64, i64, i64, i64, i64, i64) -> i64 apple_aarch64
    sig15 = (i64, i64) -> i64 tail
    sig16 = (i64, i64) -> i64 tail
    sig17 = (i64, i64) -> i64 tail
    sig18 = (i64, i64, i64, i64, i64, i64, i64) -> i64 apple_aarch64
    sig19 = (i64, i64) -> i64 tail
    fn0 = colocated u0:15 sig0
    fn1 = colocated u0:18 sig1
    fn2 = u0:4 sig2
    fn3 = colocated u0:15 sig4
    fn4 = colocated u0:18 sig5
    fn5 = u0:4 sig6
    fn6 = colocated u0:15 sig8
    fn7 = colocated u0:18 sig9
    fn8 = u0:4 sig10
    fn9 = colocated u0:15 sig12
    fn10 = colocated u0:18 sig13
    fn11 = u0:4 sig14
    fn12 = colocated u0:15 sig16
    fn13 = colocated u0:18 sig17
    fn14 = u0:4 sig18

block0(v0: i64, v1: i64):
    v2 = symbol_value.i64 gv0
    v3 = iadd_imm v2, 8
    v4 = iadd_imm v3, 3
    v5 = global_value.i64 gv1
    v6 = iadd_imm v5, 8
    v7 = iconst.i64 1
    v8 = ishl_imm v7, 1  ; v7 = 1
    v9 = iadd_imm v0, -8
    store aligned v8, v9
    v10 = iconst.i64 1
    v11 = func_addr.i64 fn0
    v12 = func_addr.i64 fn1
    v13 = iconst.i64 0
    v14 = call fn2(v4, v9, v6, v10, v11, v12, v13)  ; v10 = 1, v13 = 0
    v15 = load.i64 v14
    v16 = load.i64 v14+8
    v17 = load.i64 v14+16
    v18 = call_indirect sig3, v15(v16, v17)
    v19 = load.i64 v18
    v20 = iadd_imm v18, 8
    v21 = symbol_value.i64 gv2
    v22 = iadd_imm v21, 8
    v23 = iadd_imm v22, 3
    v24 = global_value.i64 gv3
    v25 = iadd_imm v24, 8
    v26 = iconst.i64 0
    v27 = func_addr.i64 fn3
    v28 = func_addr.i64 fn4
    v29 = iconst.i64 0
    v30 = call fn5(v23, v20, v25, v26, v27, v28, v29)  ; v26 = 0, v29 = 0
    v31 = load.i64 v30
    v32 = load.i64 v30+8
    v33 = load.i64 v30+16
    v34 = call_indirect sig7, v31(v32, v33)
    v35 = load.i64 v34
    v36 = iadd_imm v34, 8
    v37 = symbol_value.i64 gv4
    v38 = iadd_imm v37, 8
    v39 = iadd_imm v38, 3
    v40 = global_value.i64 gv5
    v41 = iadd_imm v40, 8
    v42 = iconst.i64 0
    v43 = func_addr.i64 fn6
    v44 = func_addr.i64 fn7
    v45 = iconst.i64 0
    v46 = call fn8(v39, v36, v41, v42, v43, v44, v45)  ; v42 = 0, v45 = 0
    v47 = load.i64 v46
    v48 = load.i64 v46+8
    v49 = load.i64 v46+16
    v50 = call_indirect sig11, v47(v48, v49)
    v51 = load.i64 v50
    v52 = iadd_imm v50, 8
    v53 = symbol_value.i64 gv6
    v54 = iadd_imm v53, 8
    v55 = iadd_imm v54, 3
    v56 = global_value.i64 gv7
    v57 = iadd_imm v56, 8
    v58 = iconst.i64 0
    v59 = func_addr.i64 fn9
    v60 = func_addr.i64 fn10
    v61 = iconst.i64 0
    v62 = call fn11(v55, v52, v57, v58, v59, v60, v61)  ; v58 = 0, v61 = 0
    v63 = load.i64 v62
    v64 = load.i64 v62+8
    v65 = load.i64 v62+16
    v66 = call_indirect sig15, v63(v64, v65)
    v67 = load.i64 v66
    v68 = iadd_imm v66, 8
    v69 = symbol_value.i64 gv8
    v70 = iadd_imm v69, 8
    v71 = iadd_imm v70, 3
    v72 = isub v0, v68
    v73 = load.i64 v1+8
    v74 = ishl_imm v73, 3
    v75 = iadd v74, v72
    v76 = ushr_imm v75, 3
    store v76, v1+8
    v77 = iconst.i64 0
    v78 = func_addr.i64 fn12
    v79 = func_addr.i64 fn13
    v80 = iconst.i64 1
    v81 = call fn14(v71, v68, v1, v77, v78, v79, v80)  ; v77 = 0, v80 = 1
    v82 = load.i64 v81
    v83 = load.i64 v81+8
    v84 = load.i64 v81+16
    return_call_indirect sig19, v82(v83, v84)
}


[main$__lambda_11__cps]
function u0:0(i64, i64) -> i64 tail {
    ss0 = explicit_slot 8
    gv0 = symbol colocated userextname6
    gv1 = symbol colocated userextname8
    sig0 = (i64, i64) -> i64 tail
    sig1 = (i64, i64) -> i64 tail
    sig2 = (i64, i64) -> i64 tail
    sig3 = (i64, i64, i64) -> i64 tail
    sig4 = (i64, i64, i64, i64, i64, i64, i64) -> i64 apple_aarch64
    sig5 = (i64, i64, i64) apple_aarch64
    sig6 = (i64, i64) -> i64 tail
    sig7 = (i64, i64) -> i64 tail
    sig8 = (i64, i64, i64) apple_aarch64
    sig9 = (i64, i64, i64, i64) -> i64 tail
    sig10 = (i64, i64) -> i64 tail
    sig11 = (i64, i64) -> i64 apple_aarch64
    fn0 = colocated u0:36 sig0
    fn1 = colocated u0:38 sig1
    fn2 = colocated u0:40 sig2
    fn3 = colocated u0:20 sig3
    fn4 = u0:6 sig4
    fn5 = u0:7 sig5
    fn6 = colocated u0:42 sig6
    fn7 = colocated u0:44 sig7
    fn8 = u0:8 sig8
    fn9 = u0:13 sig9
    fn10 = colocated u0:26 sig10
    fn11 = u0:1 sig11

block0(v0: i64, v1: i64):
    v2 = isub v0, v0
    v3 = load.i64 v1+8
    v4 = ishl_imm v3, 3
    v5 = iadd v4, v2
    v6 = ushr_imm v5, 3
    store v6, v1+8
    v7 = iconst.i64 1
    v8 = ishl_imm v7, 1  ; v7 = 1
    v9 = func_addr.i64 fn0
    v10 = iadd_imm v9, 3
    v11 = func_addr.i64 fn1
    v12 = iadd_imm v11, 3
    v13 = func_addr.i64 fn2
    v14 = iadd_imm v13, 3
    v15 = func_addr.i64 fn3
    stack_store v0, ss0
    v16 = stack_addr.i64 ss0
    v17 = call fn4(v16, v1, v8, v10, v12, v14, v15)
    v18 = stack_load.i64 ss0
    v19 = symbol_value.i64 gv0
    v20 = iadd_imm v19, 8
    v21 = iadd_imm v20, 3
    v22 = func_addr.i64 fn6
    v23 = iadd_imm v22, 3
    call fn5(v17, v21, v23)
    v24 = symbol_value.i64 gv1
    v25 = iadd_imm v24, 8
    v26 = iadd_imm v25, 3
    v27 = func_addr.i64 fn7
    v28 = iadd_imm v27, 3
    call fn5(v17, v26, v28)
    v29 = load.i64 v17
    v30 = func_addr.i64 fn10
    v31 = iadd_imm v30, 3
    stack_store v18, ss0
    v32 = stack_addr.i64 ss0
    v33 = call fn11(v31, v32)
    v34 = stack_load.i64 ss0
    v35 = isub v18, v34
    v36 = load.i64 v29+8
    v37 = ishl_imm v36, 3
    v38 = iadd v37, v35
    v39 = ushr_imm v38, 3
    store v39, v29+8
    return_call fn9(v34, v29, v33, v17)
}


[main$__lambda_2__cps]
function u0:0(i64, i64) -> i64 tail {
    ss0 = explicit_slot 8
    sig0 = (i64, i64, i64) -> i64 tail

block0(v0: i64, v1: i64):
    v2 = load.i64 v0
    v3 = load.i64 v0+8
    v4 = iadd_imm v0, 8
    store v3, v4
    v5 = load.i64 v1+8
    v6 = ishl_imm v5, 3
    v7 = iadd v0, v6
    v8 = load.i64 v1
    return_call_indirect sig0, v8(v7, v1, v4)
}


[main$__lambda_3__cps]
function u0:0(i64, i64) -> i64 tail {
    ss0 = explicit_slot 8
    sig0 = (i64) -> i64 apple_aarch64
    sig1 = (i64) -> i64 apple_aarch64
    sig2 = (i64, i64, i64) -> i64 tail
    fn0 = u0:0 sig0
    fn1 = u0:0 sig1

block0(v0: i64, v1: i64):
    v2 = load.i64 v0
    v3 = iconst.i64 1
    v4 = ishl_imm v3, 1  ; v3 = 1
    v5 = iconst.i64 2
    v6 = call fn0(v5)  ; v5 = 2
    store aligned v4, v6
    store aligned v2, v6+8
    v7 = iadd_imm v6, 1
    v8 = iconst.i64 2
    v9 = call fn1(v8)  ; v8 = 2
    store aligned v2, v9
    store aligned v7, v9+8
    v10 = iadd_imm v9, 1
    v11 = iadd_imm v0, 0
    store v10, v11
    v12 = load.i64 v1+8
    v13 = ishl_imm v12, 3
    v14 = iadd v0, v13
    v15 = load.i64 v1
    return_call_indirect sig2, v15(v14, v1, v11)
}


[main$__lambda_4__cps]
function u0:0(i64, i64) -> i64 tail {
    ss0 = explicit_slot 8
    sig0 = (i64) -> i64 apple_aarch64
    sig1 = (i64) -> i64 apple_aarch64
    sig2 = (i64) -> i64 apple_aarch64
    sig3 = (i64, i64, i64) -> i64 tail
    fn0 = u0:0 sig0
    fn1 = u0:0 sig1
    fn2 = u0:0 sig2

block0(v0: i64, v1: i64):
    v2 = load.i64 v0
    v3 = load.i64 v0+8
    v4 = iconst.i64 1
    v5 = ishl_imm v4, 1  ; v4 = 1
    v6 = iconst.i64 0
    v7 = call fn0(v6)  ; v6 = 0
    v8 = iadd_imm v7, 1
    v9 = iconst.i64 2
    v10 = call fn1(v9)  ; v9 = 2
    store aligned v5, v10
    store aligned v8, v10+8
    v11 = iadd_imm v10, 1
    v12 = iconst.i64 2
    v13 = call fn2(v12)  ; v12 = 2
    store aligned v3, v13
    store aligned v11, v13+8
    v14 = iadd_imm v13, 1
    v15 = iadd_imm v0, 8
    store v14, v15
    v16 = load.i64 v1+8
    v17 = ishl_imm v16, 3
    v18 = iadd v0, v17
    v19 = load.i64 v1
    return_call_indirect sig3, v19(v18, v1, v15)
}


[main$__lambda_5__cps]
function u0:0(i64, i64) -> i64 tail {
    ss0 = explicit_slot 8
    sig0 = (i64) -> i64 apple_aarch64
    sig1 = (i64, i64, i64) -> i64 tail
    fn0 = u0:0 sig0

block0(v0: i64, v1: i64):
    v2 = load.i64 v0
    v3 = iconst.i64 0
    v4 = call fn0(v3)  ; v3 = 0
    v5 = iadd_imm v4, 1
    v6 = iadd_imm v0, 0
    store v5, v6
    v7 = load.i64 v1+8
    v8 = ishl_imm v7, 3
    v9 = iadd v0, v8
    v10 = load.i64 v1
    return_call_indirect sig1, v10(v9, v1, v6)
}


[main$__lambda_6__cps]
function u0:0(i64, i64) -> i64 tail {
    ss0 = explicit_slot 8
    sig0 = (i64) -> i64 apple_aarch64
    sig1 = (i64, i64, i64) -> i64 tail
    fn0 = u0:0 sig0

block0(v0: i64, v1: i64):
    v2 = load.i64 v0
    v3 = iconst.i64 2
    v4 = call fn0(v3)  ; v3 = 2
    store aligned v2, v4
    store aligned v2, v4+8
    v5 = iadd_imm v4, 1
    v6 = iadd_imm v0, 0
    store v5, v6
    v7 = load.i64 v1+8
    v8 = ishl_imm v7, 3
    v9 = iadd v0, v8
    v10 = load.i64 v1
    return_call_indirect sig1, v10(v9, v1, v6)
}


[main$__lambda_7__cps]
function u0:0(i64, i64) -> i64 tail {
    ss0 = explicit_slot 8
    sig0 = (i64, i64, i64) -> i64 tail

block0(v0: i64, v1: i64):
    v2 = load.i64 v0
    v3 = load.i64 v0+8
    v4 = iadd_imm v0, 8
    store v3, v4
    v5 = load.i64 v1+8
    v6 = ishl_imm v5, 3
    v7 = iadd v0, v6
    v8 = load.i64 v1
    return_call_indirect sig0, v8(v7, v1, v4)
}


[main$__lambda_8__cps]
function u0:0(i64, i64) -> i64 tail {
    ss0 = explicit_slot 8
    gv0 = symbol colocated userextname0
    gv1 = symbol colocated userextname1
    gv2 = symbol colocated userextname5
    gv3 = symbol colocated userextname1
    sig0 = (i64, i64) -> i64 tail
    sig1 = (i64, i64) -> i64 tail
    sig2 = (i64, i64, i64, i64, i64, i64, i64) -> i64 apple_aarch64
    sig3 = (i64, i64) -> i64 tail
    sig4 = (i64, i64) -> i64 tail
    sig5 = (i64, i64) -> i64 tail
    sig6 = (i64, i64, i64, i64, i64, i64, i64) -> i64 apple_aarch64
    sig7 = (i64, i64) -> i64 tail
    sig8 = (i64) -> i64 apple_aarch64
    sig9 = (i64) -> i64 apple_aarch64
    sig10 = (i64, i64, i64) -> i64 tail
    fn0 = colocated u0:15 sig0
    fn1 = colocated u0:18 sig1
    fn2 = u0:4 sig2
    fn3 = colocated u0:15 sig4
    fn4 = colocated u0:18 sig5
    fn5 = u0:4 sig6
    fn6 = u0:0 sig8
    fn7 = u0:0 sig9

block0(v0: i64, v1: i64):
    v2 = load.i64 v0
    v3 = symbol_value.i64 gv0
    v4 = iadd_imm v3, 8
    v5 = iadd_imm v4, 3
    v6 = global_value.i64 gv1
    v7 = iadd_imm v6, 8
    v8 = iconst.i64 0
    v9 = func_addr.i64 fn0
    v10 = func_addr.i64 fn1
    v11 = iconst.i64 0
    v12 = call fn2(v5, v0, v7, v8, v9, v10, v11)  ; v8 = 0, v11 = 0
    v13 = load.i64 v12
    v14 = load.i64 v12+8
    v15 = load.i64 v12+16
    v16 = call_indirect sig3, v13(v14, v15)
    v17 = load.i64 v16
    v18 = iadd_imm v16, 8
    v19 = iconst.i64 1
    v20 = sshr_imm v17, 1
    v21 = iadd v20, v19  ; v19 = 1
    v22 = symbol_value.i64 gv2
    v23 = iadd_imm v22, 8
    v24 = iadd_imm v23, 3
    v25 = global_value.i64 gv3
    v26 = iadd_imm v25, 8
    v27 = ishl_imm v21, 1
    v28 = iadd_imm v18, -8
    store aligned v27, v28
    v29 = iconst.i64 1
    v30 = func_addr.i64 fn3
    v31 = func_addr.i64 fn4
    v32 = iconst.i64 0
    v33 = call fn5(v24, v28, v26, v29, v30, v31, v32)  ; v29 = 1, v32 = 0
    v34 = load.i64 v33
    v35 = load.i64 v33+8
    v36 = load.i64 v33+16
    v37 = call_indirect sig7, v34(v35, v36)
    v38 = load.i64 v37
    v39 = iadd_imm v37, 8
    v40 = iconst.i64 1
    v41 = ishl_imm v40, 1  ; v40 = 1
    v42 = iconst.i64 2
    v43 = call fn6(v42)  ; v42 = 2
    store aligned v41, v43
    store aligned v38, v43+8
    v44 = iadd_imm v43, 1
    v45 = iconst.i64 2
    v46 = call fn7(v45)  ; v45 = 2
    store aligned v2, v46
    store aligned v44, v46+8
    v47 = iadd_imm v46, 1
    v48 = iadd_imm v0, 0
    store v47, v48
    v49 = load.i64 v1+8
    v50 = ishl_imm v49, 3
    v51 = iadd v0, v50
    v52 = load.i64 v1
    return_call_indirect sig10, v52(v51, v1, v48)
}


[main$__lambda_9__cps]
function u0:0(i64, i64) -> i64 tail {
    ss0 = explicit_slot 8
    gv0 = symbol colocated userextname0
    gv1 = symbol colocated userextname1
    gv2 = symbol colocated userextname5
    gv3 = symbol colocated userextname1
    sig0 = (i64, i64) -> i64 tail
    sig1 = (i64, i64) -> i64 tail
    sig2 = (i64, i64, i64, i64, i64, i64, i64) -> i64 apple_aarch64
    sig3 = (i64, i64) -> i64 tail
    sig4 = (i64, i64) -> i64 tail
    sig5 = (i64, i64) -> i64 tail
    sig6 = (i64, i64, i64, i64, i64, i64, i64) -> i64 apple_aarch64
    sig7 = (i64, i64) -> i64 tail
    sig8 = (i64) -> i64 apple_aarch64
    sig9 = (i64) -> i64 apple_aarch64
    sig10 = (i64, i64, i64) -> i64 tail
    fn0 = colocated u0:15 sig0
    fn1 = colocated u0:18 sig1
    fn2 = u0:4 sig2
    fn3 = colocated u0:15 sig4
    fn4 = colocated u0:18 sig5
    fn5 = u0:4 sig6
    fn6 = u0:0 sig8
    fn7 = u0:0 sig9

block0(v0: i64, v1: i64):
    v2 = load.i64 v0
    v3 = symbol_value.i64 gv0
    v4 = iadd_imm v3, 8
    v5 = iadd_imm v4, 3
    v6 = global_value.i64 gv1
    v7 = iadd_imm v6, 8
    v8 = iconst.i64 0
    v9 = func_addr.i64 fn0
    v10 = func_addr.i64 fn1
    v11 = iconst.i64 0
    v12 = call fn2(v5, v0, v7, v8, v9, v10, v11)  ; v8 = 0, v11 = 0
    v13 = load.i64 v12
    v14 = load.i64 v12+8
    v15 = load.i64 v12+16
    v16 = call_indirect sig3, v13(v14, v15)
    v17 = load.i64 v16
    v18 = iadd_imm v16, 8
    v19 = iconst.i64 2
    v20 = sshr_imm v17, 1
    v21 = imul v20, v19  ; v19 = 2
    v22 = symbol_value.i64 gv2
    v23 = iadd_imm v22, 8
    v24 = iadd_imm v23, 3
    v25 = global_value.i64 gv3
    v26 = iadd_imm v25, 8
    v27 = ishl_imm v21, 1
    v28 = iadd_imm v18, -8
    store aligned v27, v28
    v29 = iconst.i64 1
    v30 = func_addr.i64 fn3
    v31 = func_addr.i64 fn4
    v32 = iconst.i64 0
    v33 = call fn5(v24, v28, v26, v29, v30, v31, v32)  ; v29 = 1, v32 = 0
    v34 = load.i64 v33
    v35 = load.i64 v33+8
    v36 = load.i64 v33+16
    v37 = call_indirect sig7, v34(v35, v36)
    v38 = load.i64 v37
    v39 = iadd_imm v37, 8
    v40 = iconst.i64 1
    v41 = ishl_imm v40, 1  ; v40 = 1
    v42 = iconst.i64 2
    v43 = call fn6(v42)  ; v42 = 2
    store aligned v41, v43
    store aligned v38, v43+8
    v44 = iadd_imm v43, 1
    v45 = iconst.i64 2
    v46 = call fn7(v45)  ; v45 = 2
    store aligned v2, v46
    store aligned v44, v46+8
    v47 = iadd_imm v46, 1
    v48 = iadd_imm v0, 0
    store v47, v48
    v49 = load.i64 v1+8
    v50 = ishl_imm v49, 3
    v51 = iadd v0, v50
    v52 = load.i64 v1
    return_call_indirect sig10, v52(v51, v1, v48)
}


[__main__]
function u0:0() -> i64 fast {
    sig0 = () -> i64 apple_aarch64
    sig1 = (i64) -> i64 tail
    fn0 = u0:2 sig0
    fn1 = colocated u0:21 sig1

block0:
    v0 = call fn0()
    v1 = call fn1(v0)
    return v1
}
