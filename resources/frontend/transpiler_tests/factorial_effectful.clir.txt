CLIR
========
[factorial__specialized]
function u0:0(i64, i64) -> i64 tail {
    ss0 = explicit_slot 8
    sig0 = (i64, i64) -> i64 tail
    fn0 = colocated u0:20 sig0

block0(v0: i64, v1: i64):
    brif v1, block3, block2

block2:
    v4 = iconst.i64 1
    jump block1(v4, v0)  ; v4 = 1

block3:
    v5 = iconst.i64 1
    v6 = isub.i64 v1, v5  ; v5 = 1
    v7 = call fn0(v0, v6)
    v8 = imul.i64 v1, v7
    jump block1(v8, v0)

block1(v2: i64, v3: i64):
    return v2
}


[main__specialized]
function u0:0(i64) -> i64 tail {
    ss0 = explicit_slot 8
    gv0 = symbol colocated userextname0
    sig0 = (i64) -> i64 apple_aarch64
    sig1 = (i64, i64) -> i64 tail
    sig2 = (i64, i64, i64) -> i64 tail
    sig3 = (i64, i64, i64, i64, i64, i64, i64) -> i64 apple_aarch64
    sig4 = (i64, i64, i64, i64) -> i64 tail
    sig5 = (i64, i64) -> i64 tail
    sig6 = (i64, i64) -> i64 apple_aarch64
    fn0 = u0:0 sig0
    fn1 = colocated u0:22 sig1
    fn2 = colocated u0:19 sig2
    fn3 = u0:6 sig3
    fn4 = u0:12 sig4
    fn5 = colocated u0:24 sig5
    fn6 = u0:1 sig6

block0(v0: i64):
    v1 = global_value.i64 gv0
    v2 = iadd_imm v1, 8
    v3 = iconst.i64 0
    v4 = call fn0(v3)  ; v3 = 0
    v5 = iadd_imm v4, 1
    v6 = iconst.i64 3
    v7 = iconst.i64 3
    v8 = func_addr.i64 fn1
    v9 = iadd_imm v8, 3
    v10 = func_addr.i64 fn2
    stack_store v0, ss0
    v11 = stack_addr.i64 ss0
    v12 = call fn3(v11, v2, v5, v6, v7, v9, v10)  ; v6 = 3, v7 = 3
    v13 = stack_load.i64 ss0
    v14 = load.i64 v12
    v15 = load.i64 v14
    v16 = func_addr.i64 fn5
    v17 = iadd_imm v16, 3
    stack_store v13, ss0
    v18 = stack_addr.i64 ss0
    v19 = call fn6(v17, v18)
    v20 = stack_load.i64 ss0
    v21 = iadd_imm v12, 1
    v22 = iadd_imm v20, -8
    store aligned v21, v22
    v23 = isub v13, v22
    v24 = load.i64 v15+8
    v25 = ishl_imm v24, 3
    v26 = iadd v25, v23
    v27 = ushr_imm v26, 3
    store v27, v15+8
    v28 = call fn4(v22, v15, v19, v14)
    v29 = load.i64 v28
    v30 = iadd_imm v28, 8
    v31 = sshr_imm v29, 1
    return v31
}


[main$__lambda_0__cps]
function u0:0(i64, i64) -> i64 tail {
    ss0 = explicit_slot 8
    sig0 = (i64, i64, i64) -> i64 tail

block0(v0: i64, v1: i64):
    v2 = load.i64 v0
    v3 = load.i64 v0+8
    v4 = iadd_imm v0, 8
    store v3, v4
    v5 = load.i64 v1+8
    v6 = ishl_imm v5, 3
    v7 = iadd v0, v6
    v8 = load.i64 v1
    return_call_indirect sig0, v8(v7, v1, v4)
}


[main$__lambda_1__cps]
function u0:0(i64, i64) -> i64 tail {
    ss0 = explicit_slot 8
    sig0 = (i64, i64) -> i64 tail
    sig1 = (i64, i64, i64) -> i64 tail
    fn0 = colocated u0:20 sig0

block0(v0: i64, v1: i64):
    v2 = load.i64 v0
    v3 = iconst.i64 5
    v4 = call fn0(v0, v3)  ; v3 = 5
    v5 = ishl_imm v4, 1
    v6 = iadd_imm v0, 0
    store v5, v6
    v7 = load.i64 v1+8
    v8 = ishl_imm v7, 3
    v9 = iadd v0, v8
    v10 = load.i64 v1
    return_call_indirect sig1, v10(v9, v1, v6)
}


[__main__]
function u0:0() -> i64 fast {
    sig0 = () -> i64 apple_aarch64
    sig1 = (i64) -> i64 tail
    fn0 = u0:2 sig0
    fn1 = colocated u0:21 sig1

block0:
    v0 = call fn0()
    v1 = call fn1(v0)
    return v1
}
